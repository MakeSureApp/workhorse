{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kingo\\AppData\\Local\\Temp\\ipykernel_36368\\2774585212.py\", line 4, in <module>\n",
      "    il_folders = os.listdir(\"data\")\n",
      "FileNotFoundError: [WinError 3] Системе не удается найти указанный путь: 'data'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\executing\\executing.py\", line 428, in asttext\n",
      "    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asttokens\\asttokens.py\", line 307, in __init__\n",
      "    super(ASTText, self).__init__(source_text, filename)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asttokens\\asttokens.py\", line 44, in __init__\n",
      "    source_text = six.ensure_text(source_text)\n",
      "AttributeError: module 'six' has no attribute 'ensure_text'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "il_folders = os.listdir(\"data\")\n",
    "il_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8437.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8438.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8439.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8440.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8441.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1249.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1250.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1251.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1252.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1253.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1254.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1255.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1256.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1257.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1258.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1259.JPG', 'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1260.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\FullSizeRender.jpg', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1262.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1263.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1265.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1266.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1267.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1268.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1269.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1270.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1271.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1272.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1273.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1274.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1275.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1276.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1277.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1278.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1279.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1280.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1281.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1282.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1283.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1284.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1285.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1286.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1287.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1288.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1289.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1290.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1291.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1292.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1293.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1294.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1295.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1296.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1297.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1298.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1299.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1300.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1301.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1302.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1303.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1304.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1305.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1306.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1307.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1308.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1309.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1310.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1311.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1312.JPG', 'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1313.JPG']\n",
      "['data/HIV\\\\Failure\\\\iPhone 6\\\\FullSizeRender.jpg', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1315.JPG', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1316.JPG', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1317.JPG', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1318.JPG', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1319.JPG', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1320.JPG', 'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1321.JPG', 'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8442.JPG', 'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8443.JPG', 'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8444.JPG', 'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8445.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1336.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1337.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1338.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1339.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1340.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1341.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1342.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1343.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1344.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1345.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1346.JPG', 'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1347.JPG']\n",
      "['data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1322.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1323.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1324.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1325.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1326.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1327.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1328.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1329.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1330.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1331.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1332.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1333.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1334.JPG', 'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1335.JPG', 'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8446.JPG', 'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8447.JPG', 'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8450.JPG', 'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8451.JPG', 'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8452.JPG']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " ['data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8437.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8438.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8439.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8440.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 11\\\\IMG_8441.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1249.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1250.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1251.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1252.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1253.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1254.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1255.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1256.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1257.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1258.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1259.JPG',\n",
       "  'data/Hepatitis\\\\Negative\\\\iPhone 6\\\\IMG_1260.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\FullSizeRender.jpg',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1262.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1263.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1265.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1266.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1267.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1268.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1269.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1270.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1271.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1272.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1273.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1274.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1275.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1276.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1277.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1278.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1279.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1280.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1281.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1282.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1283.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1284.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1285.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1286.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1287.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1288.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1289.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1290.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1291.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1292.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1293.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1294.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1295.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1296.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1297.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1298.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1299.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1300.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1301.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1302.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1303.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1304.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1305.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1306.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1307.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1308.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1309.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1310.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1311.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1312.JPG',\n",
       "  'data/Hepatitis\\\\Positive\\\\iPhone 6\\\\IMG_1313.JPG'],\n",
       " ['data/HIV\\\\Failure\\\\iPhone 6\\\\FullSizeRender.jpg',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1315.JPG',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1316.JPG',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1317.JPG',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1318.JPG',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1319.JPG',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1320.JPG',\n",
       "  'data/HIV\\\\Failure\\\\iPhone 6\\\\IMG_1321.JPG',\n",
       "  'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8442.JPG',\n",
       "  'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8443.JPG',\n",
       "  'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8444.JPG',\n",
       "  'data/HIV\\\\Negative\\\\iPhone 11\\\\IMG_8445.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1336.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1337.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1338.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1339.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1340.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1341.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1342.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1343.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1344.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1345.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1346.JPG',\n",
       "  'data/HIV\\\\Positive\\\\iPhone 6\\\\IMG_1347.JPG'],\n",
       " ['data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1322.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1323.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1324.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1325.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1326.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1327.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1328.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1329.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1330.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1331.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1332.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1333.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1334.JPG',\n",
       "  'data/Syphilis\\\\Failure\\\\iPhone 6\\\\IMG_1335.JPG',\n",
       "  'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8446.JPG',\n",
       "  'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8447.JPG',\n",
       "  'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8450.JPG',\n",
       "  'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8451.JPG',\n",
       "  'data/Syphilis\\\\Negative\\\\iPhone 11\\\\IMG_8452.JPG']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = []\n",
    "def refactor_data(il_folders):\n",
    "    for folder in il_folders:\n",
    "        results = glob.glob(f\"data/{folder}/*/*/*.jpg\")\n",
    "        print(results)\n",
    "        datas.append(results)\n",
    "\n",
    "refactor_data(il_folders)\n",
    "\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kingo\\AppData\\Local\\Temp\\ipykernel_36368\\1501398490.py\", line 38, in <module>\n",
      "    retval, decoded_info, points, straight_qrcode = qcd.detectAndDecodeMulti(ROI)\n",
      "cv2.error: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'detectAndDecodeMulti'\n",
      "> Overload resolution failed:\n",
      ">  - img is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'img'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\executing\\executing.py\", line 428, in asttext\n",
      "    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asttokens\\asttokens.py\", line 307, in __init__\n",
      "    super(ASTText, self).__init__(source_text, filename)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asttokens\\asttokens.py\", line 44, in __init__\n",
      "    source_text = six.ensure_text(source_text)\n",
      "AttributeError: module 'six' has no attribute 'ensure_text'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "\n",
    "qcd = cv2.QRCodeDetector()\n",
    "\n",
    "ROI = []\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load imgae, grayscale, Gaussian blur, Otsu's threshold\n",
    "image = cv2.imread('./tests/IMG_1345.JPG')\n",
    "original = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Morph close\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "close = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "# Find contours and filter for QR code\n",
    "cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "    x,y,w,h = cv2.boundingRect(approx)\n",
    "    area = cv2.contourArea(c)\n",
    "    ar = w / float(h)\n",
    "    if len(approx) == 4 and area > 1000 and (ar > .85 and ar < 1.3):\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 3)\n",
    "        ROI = original[y:y+h, x:x+w]\n",
    "        cv2.imwrite('ROI.png', ROI)\n",
    "\n",
    "retval, decoded_info, points, straight_qrcode = qcd.detectAndDecodeMulti(ROI)\n",
    "print(decoded_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.124 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.53  Python-3.9.0 torch-2.0.1+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=t_res.yaml, epochs=30, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train8\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.Detect                [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\SKB\\ETC\\Schoolbase\\datasets\\datasets\\t_res\\labels\\train... 94 images, 0 backgrounds, 0 corrupt: 100%|██████████| 94/94 [00:00<00:00, 461.90it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\SKB\\ETC\\Schoolbase\\datasets\\datasets\\t_res\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\SKB\\ETC\\Schoolbase\\datasets\\datasets\\t_res\\labels\\val... 17 images, 0 backgrounds, 0 corrupt: 100%|██████████| 17/17 [00:00<00:00, 367.27it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\SKB\\ETC\\Schoolbase\\datasets\\datasets\\t_res\\labels\\val.cache\n",
      "Plotting labels to runs\\detect\\train8\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train8\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/30         0G      1.882      4.706      1.299         23        640: 100%|██████████| 6/6 [01:18<00:00, 13.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "                   all         17         17          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/30         0G      1.692      4.318      1.233         21        640: 100%|██████████| 6/6 [01:24<00:00, 14.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n",
      "                   all         17         17   0.000734      0.536      0.001   0.000337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/30         0G      1.628      3.741      1.134         34        640: 100%|██████████| 6/6 [01:35<00:00, 15.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.63s/it]\n",
      "                   all         17         17    0.00133      0.607    0.00144   0.000791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/30         0G       1.55      2.786      1.109         24        640: 100%|██████████| 6/6 [01:39<00:00, 16.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "                   all         17         17    0.00331      0.857    0.00351    0.00183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/30         0G      1.565      2.534      1.157         27        640: 100%|██████████| 6/6 [01:32<00:00, 15.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n",
      "                   all         17         17     0.0034      0.964    0.00421     0.0021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/30         0G      1.389      2.347      1.074         23        640: 100%|██████████| 6/6 [01:31<00:00, 15.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "                   all         17         17    0.00331          1    0.00469    0.00244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/30         0G      1.416      2.194      1.072         21        640: 100%|██████████| 6/6 [01:31<00:00, 15.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.62s/it]\n",
      "                   all         17         17    0.00289      0.929     0.0247     0.0113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/30         0G      1.389      2.113      1.073         23        640: 100%|██████████| 6/6 [01:34<00:00, 15.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n",
      "                   all         17         17    0.00305      0.964      0.112     0.0663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/30         0G      1.463      1.994        1.1         32        640: 100%|██████████| 6/6 [01:35<00:00, 15.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.73s/it]\n",
      "                   all         17         17    0.00302      0.964      0.159     0.0997\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/30         0G      1.371      1.812       1.09         25        640: 100%|██████████| 6/6 [01:34<00:00, 15.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.44s/it]\n",
      "                   all         17         17    0.00282      0.929       0.23      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/30         0G      1.376      1.884      1.108         19        640: 100%|██████████| 6/6 [01:32<00:00, 15.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n",
      "                   all         17         17    0.00299      0.964      0.431      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/30         0G      1.333      1.735      1.062         30        640: 100%|██████████| 6/6 [01:37<00:00, 16.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.51s/it]\n",
      "                   all         17         17     0.0028      0.929      0.467      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/30         0G      1.358       1.74      1.084         18        640: 100%|██████████| 6/6 [01:34<00:00, 15.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "                   all         17         17    0.00269      0.893      0.435      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/30         0G      1.294      1.661       1.04         19        640: 100%|██████████| 6/6 [01:34<00:00, 15.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.26s/it]\n",
      "                   all         17         17      0.524      0.616       0.45      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/30         0G       1.37       1.52      1.076         22        640: 100%|██████████| 6/6 [01:34<00:00, 15.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.49s/it]\n",
      "                   all         17         17      0.773     0.0357      0.414      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/30         0G      1.337      1.422      1.091         21        640: 100%|██████████| 6/6 [01:31<00:00, 15.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.92s/it]\n",
      "                   all         17         17      0.998      0.214      0.698       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/30         0G      1.342      1.377      1.116         18        640: 100%|██████████| 6/6 [01:33<00:00, 15.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.90s/it]\n",
      "                   all         17         17      0.941      0.286      0.753      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/30         0G      1.248      1.387      1.074         17        640: 100%|██████████| 6/6 [01:35<00:00, 15.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.66s/it]\n",
      "                   all         17         17      0.926      0.205      0.635      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/30         0G      1.263      1.534      1.038         22        640: 100%|██████████| 6/6 [01:37<00:00, 16.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n",
      "                   all         17         17      0.829      0.718      0.833      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/30         0G      1.286      1.434      1.065         22        640: 100%|██████████| 6/6 [01:40<00:00, 16.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.93s/it]\n",
      "                   all         17         17      0.847      0.558      0.694      0.354\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/30         0G      1.201      1.538      1.034         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.70s/it]\n",
      "                   all         17         17      0.943      0.632      0.821      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/30         0G      1.283      1.402      1.076         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.65s/it]\n",
      "                   all         17         17      0.793      0.723      0.969      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/30         0G      1.203      1.427      1.042         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.03s/it]\n",
      "                   all         17         17      0.934      0.667      0.907       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/30         0G      1.188      1.375      1.052         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.83s/it]\n",
      "                   all         17         17      0.867      0.876      0.878       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/30         0G      1.172      1.296       1.02         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.03s/it]\n",
      "                   all         17         17      0.915      0.855      0.912      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/30         0G      1.184      1.333       1.05         14        640: 100%|██████████| 6/6 [01:04<00:00, 10.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.88s/it]\n",
      "                   all         17         17      0.798      0.857      0.885      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/30         0G      1.213      1.338       1.04         14        640: 100%|██████████| 6/6 [01:03<00:00, 10.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                   all         17         17      0.811      0.821      0.865      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/30         0G      1.146      1.257     0.9941         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.34s/it]\n",
      "                   all         17         17      0.882      0.775      0.821       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/30         0G      1.164      1.212      1.013         14        640: 100%|██████████| 6/6 [00:59<00:00,  9.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n",
      "                   all         17         17      0.885       0.78      0.823      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/30         0G       1.19      1.212      1.034         14        640: 100%|██████████| 6/6 [01:01<00:00, 10.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "                   all         17         17      0.922       0.72      0.847      0.564\n",
      "\n",
      "30 epochs completed in 0.754 hours.\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train8\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.53  Python-3.9.0 torch-2.0.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.48s/it]\n",
      "                   all         17         17      0.798      0.857      0.885      0.656\n",
      "                     N         17         14      0.959      0.714      0.775      0.482\n",
      "                     P         17          3      0.638          1      0.995       0.83\n",
      "Speed: 1.2ms preprocess, 105.4ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(data='t_res.yaml', epochs=30, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 Syphilis, 157.8ms\n",
      "Speed: 1.0ms preprocess, 157.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict13\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('tests/IMG_8446.JPG')\n",
    "\n",
    "model = YOLO('../weights/best_type.pt')\n",
    "\n",
    "res = model.predict(image)\n",
    "\n",
    "int(res[0].boxes.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines in test is  13.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('tests/IMG_8450.JPG')\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "img = cv2.inRange(img, (150, 60, 100), (255, 255, 255))\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11,11))\n",
    "\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, 6)\n",
    "\n",
    "contours, hier = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print('number of lines in test is ', len(contours)/2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 files belonging to 2 classes.\n",
      "Using 90 files for training.\n",
      "Using 22 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (180, 180)\n",
    "batch_size = 128\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"datasets/t_res/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Apply `data_augmentation` to the training images.\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.3183 - accuracy: 0.9111 - val_loss: 0.7292 - val_accuracy: 0.3636\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.6386 - accuracy: 0.7556 - val_loss: 0.7436 - val_accuracy: 0.3636\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.3637 - accuracy: 0.8111 - val_loss: 0.7421 - val_accuracy: 0.3636\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.2867 - accuracy: 0.8889 - val_loss: 0.7371 - val_accuracy: 0.3636\n",
      "Epoch 5/25\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kingo\\AppData\\Local\\Temp\\ipykernel_3092\\2660810289.py\", line 11, in <module>\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 947, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2496, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1862, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 499, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\executing\\executing.py\", line 428, in asttext\n",
      "    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asttokens\\asttokens.py\", line 307, in __init__\n",
      "    super(ASTText, self).__init__(source_text, filename)\n",
      "  File \"c:\\Users\\kingo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asttokens\\asttokens.py\", line 44, in __init__\n",
      "    source_text = six.ensure_text(source_text)\n",
      "AttributeError: module 'six' has no attribute 'ensure_text'\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "This image is 54.96% N and 45.04% P.\n"
     ]
    }
   ],
   "source": [
    "img = keras.utils.load_img(\n",
    "    \"datasets/t_res/P/IMG_1290.JPG\", target_size=image_size\n",
    ")\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = float(predictions[0])\n",
    "print(f\"This image is {100 * (1 - score):.2f}% N and {100 * score:.2f}% P.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
